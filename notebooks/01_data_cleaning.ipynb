{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Tech Industry Salaries\n",
    "\n",
    "This notebook handles the cleaning and preprocessing of the raw salary dataset.\n",
    "\n",
    "## Objectives:\n",
    "- Load raw data\n",
    "- Handle missing values\n",
    "- Standardize column names\n",
    "- Remove duplicates\n",
    "- Create derived features\n",
    "- Export cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw dataset\n",
    "df_raw = pd.read_csv('../data/raw/ds_salaries.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df_raw.shape}\")\n",
    "print(f\"\\nColumns: {df_raw.columns.tolist()}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Types and Missing Values:\")\n",
    "print(\"=\" * 50)\n",
    "df_info = pd.DataFrame({\n",
    "    'Column': df_raw.columns,\n",
    "    'Data Type': df_raw.dtypes,\n",
    "    'Non-Null Count': df_raw.count(),\n",
    "    'Null Count': df_raw.isnull().sum(),\n",
    "    'Null %': (df_raw.isnull().sum() / len(df_raw) * 100).round(2)\n",
    "})\n",
    "print(df_info.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"\\nDuplicate rows:\")\n",
    "    print(df_raw[df_raw.duplicated(keep=False)].sort_values(by=df_raw.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# Drop the unnamed index column if it exists\n",
    "if 'Unnamed: 0' in df_clean.columns:\n",
    "    df_clean = df_clean.drop('Unnamed: 0', axis=1)\n",
    "    print(\"✓ Dropped 'Unnamed: 0' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names (lowercase, underscores)\n",
    "df_clean.columns = df_clean.columns.str.lower().str.replace(' ', '_')\n",
    "print(\"✓ Standardized column names\")\n",
    "print(f\"New columns: {df_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize job titles (uppercase for consistency)\n",
    "df_clean['job_title'] = df_clean['job_title'].str.upper()\n",
    "print(\"✓ Standardized job titles to uppercase\")\n",
    "print(f\"\\nUnique job titles: {df_clean['job_title'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in salary_in_usd\n",
    "Q1 = df_clean['salary_in_usd'].quantile(0.25)\n",
    "Q3 = df_clean['salary_in_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 3 * IQR\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "outliers = df_clean[(df_clean['salary_in_usd'] < lower_bound) | \n",
    "                     (df_clean['salary_in_usd'] > upper_bound)]\n",
    "\n",
    "print(f\"Salary outliers detected: {len(outliers)}\")\n",
    "print(f\"Lower bound: ${lower_bound:,.0f}\")\n",
    "print(f\"Upper bound: ${upper_bound:,.0f}\")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(\"\\nOutlier examples:\")\n",
    "    print(outliers[['job_title', 'experience_level', 'salary_in_usd', 'company_location']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extreme outliers (optional - adjust based on domain knowledge)\n",
    "# For now, we'll flag but keep them for transparency\n",
    "df_clean['is_outlier'] = ((df_clean['salary_in_usd'] < lower_bound) | \n",
    "                           (df_clean['salary_in_usd'] > upper_bound)).astype(int)\n",
    "\n",
    "print(f\"✓ Flagged {df_clean['is_outlier'].sum()} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seniority level mapping\n",
    "seniority_map = {\n",
    "    'EN': 'JUNIOR',\n",
    "    'MI': 'MID',\n",
    "    'SE': 'SENIOR',\n",
    "    'EX': 'EXECUTIVE'\n",
    "}\n",
    "\n",
    "df_clean['seniority'] = df_clean['experience_level'].map(seniority_map)\n",
    "print(\"✓ Created 'seniority' column\")\n",
    "print(f\"\\nSeniority distribution:\")\n",
    "print(df_clean['seniority'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create remote work category\n",
    "def categorize_remote(ratio):\n",
    "    if ratio == 0:\n",
    "        return 'On-site'\n",
    "    elif ratio == 50:\n",
    "        return 'Hybrid'\n",
    "    elif ratio == 100:\n",
    "        return 'Remote'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df_clean['work_setting'] = df_clean['remote_ratio'].apply(categorize_remote)\n",
    "print(\"✓ Created 'work_setting' column\")\n",
    "print(f\"\\nWork setting distribution:\")\n",
    "print(df_clean['work_setting'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create company size label\n",
    "size_map = {\n",
    "    'S': 'Small',\n",
    "    'M': 'Medium',\n",
    "    'L': 'Large'\n",
    "}\n",
    "\n",
    "df_clean['company_size_label'] = df_clean['company_size'].map(size_map)\n",
    "print(\"✓ Created 'company_size_label' column\")\n",
    "print(f\"\\nCompany size distribution:\")\n",
    "print(df_clean['company_size_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create job category based on job title\n",
    "def categorize_job(title):\n",
    "    title = title.upper()\n",
    "    if 'DATA SCIENTIST' in title or 'DATA SCIENCE' in title:\n",
    "        return 'Data Science'\n",
    "    elif 'DATA ENGINEER' in title or 'DATA ENGINEERING' in title:\n",
    "        return 'Data Engineering'\n",
    "    elif 'DATA ANALYST' in title or 'ANALYST' in title:\n",
    "        return 'Data Analytics'\n",
    "    elif 'MACHINE LEARNING' in title or 'ML ENGINEER' in title or 'ML ' in title:\n",
    "        return 'Machine Learning'\n",
    "    elif 'DIRECTOR' in title or 'HEAD OF' in title or 'MANAGER' in title:\n",
    "        return 'Management'\n",
    "    elif 'RESEARCH' in title:\n",
    "        return 'Research'\n",
    "    elif 'AI' in title or 'ARTIFICIAL INTELLIGENCE' in title:\n",
    "        return 'AI/ML'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df_clean['job_category'] = df_clean['job_title'].apply(categorize_job)\n",
    "print(\"✓ Created 'job_category' column\")\n",
    "print(f\"\\nJob category distribution:\")\n",
    "print(df_clean['job_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create salary bands\n",
    "def salary_band(salary):\n",
    "    if salary < 50000:\n",
    "        return '<50K'\n",
    "    elif salary < 100000:\n",
    "        return '50K-100K'\n",
    "    elif salary < 150000:\n",
    "        return '100K-150K'\n",
    "    elif salary < 200000:\n",
    "        return '150K-200K'\n",
    "    else:\n",
    "        return '200K+'\n",
    "\n",
    "df_clean['salary_band'] = df_clean['salary_in_usd'].apply(salary_band)\n",
    "print(\"✓ Created 'salary_band' column\")\n",
    "print(f\"\\nSalary band distribution:\")\n",
    "print(df_clean['salary_band'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check for missing values\n",
    "print(\"Missing values in cleaned dataset:\")\n",
    "print(\"=\" * 50)\n",
    "missing = df_clean.isnull().sum()\n",
    "missing_pct = (missing / len(df_clean) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print(\"\\n✓ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(\"=\" * 50)\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for cleaned data\n",
    "print(\"\\nSummary of cleaned dataset:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total records: {len(df_clean):,}\")\n",
    "print(f\"Total columns: {len(df_clean.columns)}\")\n",
    "print(f\"Years covered: {df_clean['work_year'].min()} - {df_clean['work_year'].max()}\")\n",
    "print(f\"Countries: {df_clean['company_location'].nunique()}\")\n",
    "print(f\"Job titles: {df_clean['job_title'].nunique()}\")\n",
    "print(f\"\\nSalary range (USD): ${df_clean['salary_in_usd'].min():,.0f} - ${df_clean['salary_in_usd'].max():,.0f}\")\n",
    "print(f\"Mean salary (USD): ${df_clean['salary_in_usd'].mean():,.0f}\")\n",
    "print(f\"Median salary (USD): ${df_clean['salary_in_usd'].median():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "output_path = '../data/cleaned/ds_salaries_cleaned.csv'\n",
    "df_clean.to_csv(output_path, index=False)\n",
    "print(f\"✓ Cleaned data saved to: {output_path}\")\n",
    "print(f\"\\nFinal dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of cleaned data\n",
    "print(\"\\nSample of cleaned data:\")\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column overview\n",
    "print(\"\\nFinal columns:\")\n",
    "print(\"=\" * 50)\n",
    "for i, col in enumerate(df_clean.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Cleaning Steps Completed:\n",
    "1. ✓ Loaded raw data\n",
    "2. ✓ Removed unnecessary index column\n",
    "3. ✓ Standardized column names\n",
    "4. ✓ Standardized job titles\n",
    "5. ✓ Identified and flagged outliers\n",
    "6. ✓ Created derived features:\n",
    "   - seniority (readable experience level)\n",
    "   - work_setting (remote/hybrid/on-site)\n",
    "   - company_size_label (readable size)\n",
    "   - job_category (grouped job types)\n",
    "   - salary_band (salary ranges)\n",
    "7. ✓ Performed data quality checks\n",
    "8. ✓ Exported cleaned dataset\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to `02_analysis.ipynb` for statistical analysis\n",
    "- Explore salary trends by role, location, and experience\n",
    "- Compare remote vs on-site compensation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
